{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nl2tU6kL8Ot3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-05 17:17:03.547577: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: NVIDIA GeForce RTX 3080 major: 8 minor: 6 memoryClockRate(GHz): 1.71\n",
            "pciBusID: 0000:65:00.0\n",
            "2022-05-05 17:17:03.547717: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory\n",
            "2022-05-05 17:17:03.547753: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory\n",
            "2022-05-05 17:17:03.547779: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory\n",
            "2022-05-05 17:17:03.547803: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory\n",
            "2022-05-05 17:17:03.547828: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory\n",
            "2022-05-05 17:17:03.547963: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory\n",
            "2022-05-05 17:17:03.547990: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory\n",
            "2022-05-05 17:17:03.547994: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1641] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n",
            "2022-05-05 17:17:03.548019: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2022-05-05 17:17:03.548024: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2022-05-05 17:17:03.548027: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# %tensorflow_version 1.x\n",
        "#%pip install tensorflow==1.15\n",
        "from time import time\n",
        "from scipy.sparse import csc_matrix\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import h5py\n",
        "tf.test.is_gpu_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pcyWCv_WvSKC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.15.0\n"
          ]
        }
      ],
      "source": [
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4A9uU1WloQ2"
      },
      "source": [
        "# Data Loader Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "cq3KEUaVo1o3"
      },
      "outputs": [],
      "source": [
        "def load_data_100k(path='./', delimiter='\\t'):\n",
        "    # The resultant matrix is of shape: number of movies x number of users\n",
        "    # Content are the ratings of the users for the movies\n",
        "\n",
        "    # 10000 x 4 matrix, train for first 8000 rows, test for last 2000 rows\n",
        "    # column 1: user id\n",
        "    # column 2: movie id\n",
        "    # column 3: UNKNOWN\n",
        "    # column 4: rating\n",
        "    train = np.loadtxt(path+'movielens_100k_u1.base', skiprows=0, delimiter=delimiter).astype('int32')\n",
        "    test = np.loadtxt(path+'movielens_100k_u1.test', skiprows=0, delimiter=delimiter).astype('int32')\n",
        "    total = np.concatenate((train, test), axis=0)\n",
        "\n",
        "    n_u = np.unique(total[:,0]).size  # num of users\n",
        "    n_m = np.unique(total[:,1]).size  # num of movies\n",
        "    n_train = train.shape[0]  # num of training ratings\n",
        "    n_test = test.shape[0]  # num of test ratings\n",
        "\n",
        "    train_r = np.zeros((n_m, n_u), dtype='float32')\n",
        "    test_r = np.zeros((n_m, n_u), dtype='float32')\n",
        "\n",
        "    for i in range(n_train):\n",
        "        train_r[train[i,1]-1, train[i,0]-1] = train[i,2]\n",
        "\n",
        "    for i in range(n_test):\n",
        "        test_r[test[i,1]-1, test[i,0]-1] = test[i,2]\n",
        "\n",
        "    train_m = np.greater(train_r, 1e-12).astype('float32')  # masks indicating non-zero entries\n",
        "    test_m = np.greater(test_r, 1e-12).astype('float32')\n",
        "\n",
        "    print('data matrix loaded')\n",
        "    print('num of users: {}'.format(n_u))\n",
        "    print('num of movies: {}'.format(n_m))\n",
        "    print('num of training ratings: {}'.format(n_train))\n",
        "    print('num of test ratings: {}'.format(n_test))\n",
        "\n",
        "    return n_m, n_u, train_r, train_m, test_r, test_m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "P3e8Xg3us8g7"
      },
      "outputs": [],
      "source": [
        "def load_data_1m(path='./', delimiter='::', frac=0.1, seed=1234):\n",
        "\n",
        "    tic = time()\n",
        "    print('reading data...')\n",
        "    data = np.loadtxt(path+'movielens_1m_dataset.dat', skiprows=0, delimiter=delimiter).astype('int32')\n",
        "    print('taken', time() - tic, 'seconds')\n",
        "\n",
        "    n_u = np.unique(data[:,0]).size  # num of users\n",
        "    n_m = np.unique(data[:,1]).size  # num of movies\n",
        "    n_r = data.shape[0]  # num of ratings\n",
        "\n",
        "    udict = {}\n",
        "    for i, u in enumerate(np.unique(data[:,0]).tolist()):\n",
        "        udict[u] = i\n",
        "    mdict = {}\n",
        "    for i, m in enumerate(np.unique(data[:,1]).tolist()):\n",
        "        mdict[m] = i\n",
        "\n",
        "    np.random.seed(seed)\n",
        "    idx = np.arange(n_r)\n",
        "    np.random.shuffle(idx)\n",
        "\n",
        "    train_r = np.zeros((n_m, n_u), dtype='float32')\n",
        "    test_r = np.zeros((n_m, n_u), dtype='float32')\n",
        "\n",
        "    for i in range(n_r):\n",
        "        u_id = data[idx[i], 0]\n",
        "        m_id = data[idx[i], 1]\n",
        "        r = data[idx[i], 2]\n",
        "\n",
        "        if i < int(frac * n_r):\n",
        "            test_r[mdict[m_id], udict[u_id]] = r\n",
        "        else:\n",
        "            train_r[mdict[m_id], udict[u_id]] = r\n",
        "\n",
        "    train_m = np.greater(train_r, 1e-12).astype('float32')  # masks indicating non-zero entries\n",
        "    test_m = np.greater(test_r, 1e-12).astype('float32')\n",
        "\n",
        "    print('data matrix loaded')\n",
        "    print('num of users: {}'.format(n_u))\n",
        "    print('num of movies: {}'.format(n_m))\n",
        "    print('num of training ratings: {}'.format(n_r - int(frac * n_r)))\n",
        "    print('num of test ratings: {}'.format(int(frac * n_r)))\n",
        "\n",
        "    return n_m, n_u, train_r, train_m, test_r, test_m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7rMjcbLvhtRs"
      },
      "outputs": [],
      "source": [
        "def load_matlab_file(path_file, name_field):\n",
        "    \n",
        "    db = h5py.File(path_file, 'r')\n",
        "    ds = db[name_field]\n",
        "\n",
        "    try:\n",
        "        if 'ir' in ds.keys():\n",
        "            data = np.asarray(ds['data'])\n",
        "            ir   = np.asarray(ds['ir'])\n",
        "            jc   = np.asarray(ds['jc'])\n",
        "            out  = csc_matrix((data, ir, jc)).astype(np.float32)\n",
        "    except AttributeError:\n",
        "        out = np.asarray(ds).astype(np.float32).T\n",
        "\n",
        "    db.close()\n",
        "\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "g6pIUrkza2zv"
      },
      "outputs": [],
      "source": [
        "def load_data_monti(path='./'):\n",
        "\n",
        "    M = load_matlab_file(path+'douban_monti_dataset.mat', 'M')\n",
        "    Otraining = load_matlab_file(path+'douban_monti_dataset.mat', 'Otraining') * M\n",
        "    Otest = load_matlab_file(path+'douban_monti_dataset.mat', 'Otest') * M\n",
        "\n",
        "    n_u = M.shape[0]  # num of users\n",
        "    n_m = M.shape[1]  # num of movies\n",
        "    n_train = Otraining[np.where(Otraining)].size  # num of training ratings\n",
        "    n_test = Otest[np.where(Otest)].size  # num of test ratings\n",
        "\n",
        "    train_r = Otraining.T\n",
        "    test_r = Otest.T\n",
        "\n",
        "    train_m = np.greater(train_r, 1e-12).astype('float32')  # masks indicating non-zero entries\n",
        "    test_m = np.greater(test_r, 1e-12).astype('float32')\n",
        "\n",
        "    print('data matrix loaded')\n",
        "    print('num of users: {}'.format(n_u))\n",
        "    print('num of movies: {}'.format(n_m))\n",
        "    print('num of training ratings: {}'.format(n_train))\n",
        "    print('num of test ratings: {}'.format(n_test))\n",
        "\n",
        "    return n_m, n_u, train_r, train_m, test_r, test_m"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_8kEkg9mlIW"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "0fkA1WpmipzF"
      },
      "outputs": [],
      "source": [
        "# Insert the path of a data directory by yourself (e.g., '/content/.../data')\n",
        "# .-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
        "data_path = 'data'\n",
        "# .-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ijlu0lXQioYM"
      },
      "outputs": [],
      "source": [
        "# Select a dataset among 'ML-1M', 'ML-100K', and 'Douban'\n",
        "# .-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
        "dataset = 'ML-100K'\n",
        "# .-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "sJqSSY33mgkw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data matrix loaded\n",
            "num of users: 943\n",
            "num of movies: 1682\n",
            "num of training ratings: 80000\n",
            "num of test ratings: 20000\n"
          ]
        }
      ],
      "source": [
        "# Data Load\n",
        "try:\n",
        "    if dataset == 'ML-100K':\n",
        "        path = data_path + '/MovieLens_100K/'\n",
        "        n_m, n_u, train_r, train_m, test_r, test_m = load_data_100k(path=path, delimiter='\\t')\n",
        "\n",
        "    elif dataset == 'ML-1M':\n",
        "        path = data_path + '/MovieLens_1M/'\n",
        "        n_m, n_u, train_r, train_m, test_r, test_m = load_data_1m(path=path, delimiter='::', frac=0.1, seed=1234)\n",
        "\n",
        "    elif dataset == 'Douban':\n",
        "        path = data_path + '/Douban_monti/'\n",
        "        n_m, n_u, train_r, train_m, test_r, test_m = load_data_monti(path=path)\n",
        "\n",
        "    else:\n",
        "        raise ValueError\n",
        "\n",
        "except ValueError:\n",
        "    print('Error: Unable to load data')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQMtA9yml-gp"
      },
      "source": [
        "# Hyperparameter Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "nGCdp_FlobOK"
      },
      "outputs": [],
      "source": [
        "# Common hyperparameter settings\n",
        "n_hid = 500\n",
        "n_dim = 5\n",
        "n_layers = 2\n",
        "gk_size = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "344bwGB0cWXp"
      },
      "outputs": [],
      "source": [
        "# Different hyperparameter settings for each dataset\n",
        "if dataset == 'ML-100K':\n",
        "    lambda_2 = 20.  # l2 regularisation\n",
        "    lambda_s = 0.006\n",
        "    iter_p = 5  # optimisation\n",
        "    iter_f = 5\n",
        "    epoch_p = 30  # training epoch\n",
        "    epoch_f = 60\n",
        "    dot_scale = 1  # scaled dot product\n",
        "\n",
        "elif dataset == 'ML-1M':\n",
        "    lambda_2 = 70.\n",
        "    lambda_s = 0.018\n",
        "    iter_p = 50\n",
        "    iter_f = 10\n",
        "    epoch_p = 20\n",
        "    epoch_f = 30\n",
        "    dot_scale = 0.5\n",
        "\n",
        "elif dataset == 'Douban':\n",
        "    lambda_2 = 10.\n",
        "    lambda_s = 0.022\n",
        "    iter_p = 5\n",
        "    iter_f = 5\n",
        "    epoch_p = 20\n",
        "    epoch_f = 60\n",
        "    dot_scale = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "b94aimX3nAMI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tmp/ipykernel_34511/2682195965.py:1: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "R = tf.placeholder(\"float\", [n_m, n_u])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sWtU4-pmDDT"
      },
      "source": [
        "# Network Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "wX2wREO09zde"
      },
      "outputs": [],
      "source": [
        "def local_kernel(u, v):\n",
        "    # u - v: [n_u, n_in, n_dim]\n",
        "    dist = tf.norm(u - v, ord=2, axis=2) # dist: [n_u, n_in]\n",
        "    hat = tf.maximum(0., 1. - dist**2) # hat: [n_u, n_in]\n",
        "\n",
        "    return hat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "c88l9LYr9175"
      },
      "outputs": [],
      "source": [
        "def kernel_layer(x, n_hid=n_hid, n_dim=n_dim, activation=tf.nn.sigmoid, lambda_s=lambda_s, lambda_2=lambda_2, name=''):\n",
        "\n",
        "    with tf.variable_scope(name, reuse=tf.AUTO_REUSE):\n",
        "        W = tf.get_variable('W', [x.shape[1], n_hid])\n",
        "        n_in = x.get_shape().as_list()[1]\n",
        "        u = tf.get_variable('u', initializer=tf.random.truncated_normal([n_in, 1, n_dim], 0., 1e-3))\n",
        "        v = tf.get_variable('v', initializer=tf.random.truncated_normal([1, n_hid, n_dim], 0., 1e-3))\n",
        "        b = tf.get_variable('b', [n_hid])\n",
        "\n",
        "    w_hat = local_kernel(u, v)\n",
        "    \n",
        "    sparse_reg = tf.contrib.layers.l2_regularizer(lambda_s)\n",
        "    sparse_reg_term = tf.contrib.layers.apply_regularization(sparse_reg, [w_hat])\n",
        "    \n",
        "    l2_reg = tf.contrib.layers.l2_regularizer(lambda_2)\n",
        "    l2_reg_term = tf.contrib.layers.apply_regularization(l2_reg, [W])\n",
        "\n",
        "    W_eff = W * w_hat  # Local kernelised weight matrix\n",
        "    y = tf.matmul(x, W_eff) + b\n",
        "    y = activation(y)\n",
        "\n",
        "    return y, sparse_reg_term + l2_reg_term"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "rlb95FmRVATa"
      },
      "outputs": [],
      "source": [
        "def global_kernel(input, gk_size, dot_scale):\n",
        "\n",
        "    avg_pooling = tf.reduce_mean(input, axis=1)  # Item (axis=1) based average pooling\n",
        "    avg_pooling = tf.reshape(avg_pooling, [1, -1])\n",
        "    n_kernel = avg_pooling.shape[1].value\n",
        "\n",
        "    conv_kernel = tf.get_variable('conv_kernel', initializer=tf.random.truncated_normal([n_kernel, gk_size**2], stddev=0.1))\n",
        "    gk = tf.matmul(avg_pooling, conv_kernel) * dot_scale  # Scaled dot product\n",
        "    gk = tf.reshape(gk, [gk_size, gk_size, 1, 1])\n",
        "\n",
        "    return gk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "jTLi_65XzIbH"
      },
      "outputs": [],
      "source": [
        "def global_conv(input, W):\n",
        "\n",
        "    input = tf.reshape(input, [1, input.shape[0], input.shape[1], 1])\n",
        "    conv2d = tf.nn.relu(tf.nn.conv2d(input, W, strides=[1,1,1,1], padding='SAME'))\n",
        "\n",
        "    return tf.reshape(conv2d, [conv2d.shape[1], conv2d.shape[2]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8sQCwrSmKG4"
      },
      "source": [
        "# Network Instantiation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOtWj1SCo1RW"
      },
      "source": [
        "## Pre-training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "7teUrgWagpW0"
      },
      "outputs": [],
      "source": [
        "y = R\n",
        "reg_losses = None\n",
        "\n",
        "for i in range(n_layers):\n",
        "    y, reg_loss = kernel_layer(y, name=str(i))\n",
        "    reg_losses = reg_loss if reg_losses is None else reg_losses + reg_loss\n",
        "\n",
        "pred_p, reg_loss = kernel_layer(y, n_u, activation=tf.identity, name='out')\n",
        "reg_losses = reg_losses + reg_loss\n",
        "\n",
        "# L2 loss\n",
        "diff = train_m * (train_r - pred_p)\n",
        "sqE = tf.nn.l2_loss(diff)\n",
        "loss_p = sqE + reg_losses\n",
        "\n",
        "optimizer_p = tf.contrib.opt.ScipyOptimizerInterface(loss_p, options={'disp': True, 'maxiter': iter_p, 'maxcor': 10}, method='L-BFGS-B')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IEBsNhNo4Cj"
      },
      "source": [
        "## Fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "OiTXqnN6zLXQ"
      },
      "outputs": [],
      "source": [
        "y = R\n",
        "reg_losses = None\n",
        "\n",
        "for i in range(n_layers):\n",
        "    y, _ = kernel_layer(y, name=str(i))\n",
        "\n",
        "y_dash, _ = kernel_layer(y, n_u, activation=tf.identity, name='out')\n",
        "\n",
        "gk = global_kernel(y_dash, gk_size, dot_scale)  # Global kernel\n",
        "y_hat = global_conv(train_r, gk)  # Global kernel-based rating matrix\n",
        "\n",
        "for i in range(n_layers):\n",
        "    y_hat, reg_loss = kernel_layer(y_hat, name=str(i))\n",
        "    reg_losses = reg_loss if reg_losses is None else reg_losses + reg_loss\n",
        "\n",
        "pred_f, reg_loss = kernel_layer(y_hat, n_u, activation=tf.identity, name='out')\n",
        "reg_losses = reg_losses + reg_loss\n",
        "\n",
        "# L2 loss\n",
        "diff = train_m * (train_r - pred_f)\n",
        "sqE = tf.nn.l2_loss(diff)\n",
        "loss_f = sqE + reg_losses\n",
        "\n",
        "optimizer_f = tf.contrib.opt.ScipyOptimizerInterface(loss_f, options={'disp': True, 'maxiter': iter_f, 'maxcor': 10}, method='L-BFGS-B')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sETwz58aK6y6"
      },
      "source": [
        "# Evaluation code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "vyReXxgac3KH"
      },
      "outputs": [],
      "source": [
        "def dcg_k(score_label, k):\n",
        "    dcg, i = 0., 0\n",
        "    for s in score_label:\n",
        "        if i < k:\n",
        "            dcg += (2**s[1]-1) / np.log2(2+i)\n",
        "            i += 1\n",
        "    return dcg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "jwsSR-8ZdGWo"
      },
      "outputs": [],
      "source": [
        "def ndcg_k(y_hat, y, k):\n",
        "    score_label = np.stack([y_hat, y], axis=1).tolist()\n",
        "    score_label = sorted(score_label, key=lambda d:d[0], reverse=True)\n",
        "    score_label_ = sorted(score_label, key=lambda d:d[1], reverse=True)\n",
        "    norm, i = 0., 0\n",
        "    for s in score_label_:\n",
        "        if i < k:\n",
        "            norm += (2**s[1]-1) / np.log2(2+i)\n",
        "            i += 1\n",
        "    dcg = dcg_k(score_label, k)\n",
        "    return dcg / norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "yy9eQS51pbhj"
      },
      "outputs": [],
      "source": [
        "def call_ndcg(y_hat, y):\n",
        "    ndcg_sum, num = 0, 0\n",
        "    y_hat, y = y_hat.T, y.T\n",
        "    n_users = y.shape[0]\n",
        "\n",
        "    for i in range(n_users):\n",
        "        y_hat_i = y_hat[i][np.where(y[i])]\n",
        "        y_i = y[i][np.where(y[i])]\n",
        "\n",
        "        if y_i.shape[0] < 2:\n",
        "            continue\n",
        "\n",
        "        ndcg_sum += ndcg_k(y_hat_i, y_i, y_i.shape[0])  # user-wise calculation\n",
        "        num += 1\n",
        "\n",
        "    return ndcg_sum / num"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXXQjeMxmYEC"
      },
      "source": [
        "# Training and Test Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "UZ35Zoha-Eue"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tmp/ipykernel_28827/864368156.py:5: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /tmp/ipykernel_28827/864368156.py:7: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-05 16:54:19.447167: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: NVIDIA GeForce RTX 3080 major: 8 minor: 6 memoryClockRate(GHz): 1.71\n",
            "pciBusID: 0000:65:00.0\n",
            "2022-05-05 16:54:19.447215: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2022-05-05 16:54:19.447223: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2022-05-05 16:54:19.447229: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2022-05-05 16:54:19.447238: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2022-05-05 16:54:19.447244: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2022-05-05 16:54:19.447249: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2022-05-05 16:54:19.447255: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-05-05 16:54:19.447398: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2022-05-05 16:54:19.448136: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: NVIDIA GeForce RTX 3080 major: 8 minor: 6 memoryClockRate(GHz): 1.71\n",
            "pciBusID: 0000:65:00.0\n",
            "2022-05-05 16:54:19.448167: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2022-05-05 16:54:19.448175: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2022-05-05 16:54:19.448181: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2022-05-05 16:54:19.448186: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2022-05-05 16:54:19.448193: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2022-05-05 16:54:19.448199: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2022-05-05 16:54:19.448206: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-05-05 16:54:19.448343: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2022-05-05 16:54:19.448364: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2022-05-05 16:54:19.448369: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2022-05-05 16:54:19.448372: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2022-05-05 16:54:19.448527: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9312 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:65:00.0, compute capability: 8.6)\n",
            "2022-05-05 16:58:43.770135: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2022-05-05 16:59:51.011813: E tensorflow/stream_executor/cuda/cuda_blas.cc:428] failed to run cuBLAS routine: CUBLAS_STATUS_EXECUTION_FAILED\n"
          ]
        },
        {
          "ename": "InternalError",
          "evalue": "2 root error(s) found.\n  (0) Internal: Blas GEMM launch failed : a.shape=(1682, 500), b.shape=(500, 500), m=1682, n=500, k=500\n\t [[node MatMul_1 (defined at home/leegenux/.conda/envs/tf1/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1748) ]]\n\t [[concat_1/_31]]\n  (1) Internal: Blas GEMM launch failed : a.shape=(1682, 500), b.shape=(500, 500), m=1682, n=500, k=500\n\t [[node MatMul_1 (defined at home/leegenux/.conda/envs/tf1/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1748) ]]\n0 successful operations.\n0 derived errors ignored.\n\nOriginal stack trace for 'MatMul_1':\n  File \"home/leegenux/.conda/envs/tf1/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"home/leegenux/.conda/envs/tf1/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"home/leegenux/.conda/envs/tf1/lib/python3.7/site-packages/ipykernel_launcher.py\", line 17, in <module>\n    app.launch_new_instance()\n  File \"home/leegenux/.conda/envs/tf1/lib/python3.7/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n    app.start()\n  File \"home/leegenux/.conda/envs/tf1/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 712, in start\n    self.io_loop.start()\n  File \"home/leegenux/.conda/envs/tf1/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"home/leegenux/.conda/envs/tf1/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n    self._run_once()\n  File \"home/leegenux/.conda/envs/tf1/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n    handle._run()\n  File \"home/leegenux/.conda/envs/tf1/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"home/leegenux/.conda/envs/tf1/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 504, in dispatch_queue\n    await self.process_one()\n  File \"home/leegenux/.conda/envs/tf1/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 493, in process_one\n    await dispatch(*args)\n  File \"home/leegenux/.conda/envs/tf1/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 400, in dispatch_shell\n    await result\n  File \"home/leegenux/.conda/envs/tf1/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 724, in execute_request\n    reply_content = await reply_content\n  File \"home/leegenux/.conda/envs/tf1/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 387, in do_execute\n    cell_id=cell_id,\n  File \"home/leegenux/.conda/envs/tf1/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"home/leegenux/.conda/envs/tf1/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n    raw_cell, store_history, silent, shell_futures, cell_id\n  File \"home/leegenux/.conda/envs/tf1/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3029, in _run_cell\n    return runner(coro)\n  File \"home/leegenux/.conda/envs/tf1/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n    coro.send(None)\n  File \"home/leegenux/.conda/envs/tf1/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"home/leegenux/.conda/envs/tf1/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3472, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"home/leegenux/.conda/envs/tf1/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3552, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"tmp/ipykernel_28827/1516854235.py\", line 5, in <module>\n    y, reg_loss = kernel_layer(y, name=str(i))\n  File \"tmp/ipykernel_28827/1127187019.py\", line 19, in kernel_layer\n    y = tf.matmul(x, W_eff) + b\n  File \"home/leegenux/.conda/envs/tf1/lib/python3.7/site-packages/tensorflow_core/python/util/dispatch.py\", line 180, in wrapper\n    return target(*args, **kwargs)\n  File \"home/leegenux/.conda/envs/tf1/lib/python3.7/site-packages/tensorflow_core/python/ops/math_ops.py\", line 2754, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"home/leegenux/.conda/envs/tf1/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_math_ops.py\", line 6136, in mat_mul\n    name=name)\n  File \"home/leegenux/.conda/envs/tf1/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n  File \"home/leegenux/.conda/envs/tf1/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"home/leegenux/.conda/envs/tf1/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"home/leegenux/.conda/envs/tf1/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"home/leegenux/.conda/envs/tf1/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m~/.conda/envs/tf1/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.conda/envs/tf1/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.conda/envs/tf1/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInternalError\u001b[0m: 2 root error(s) found.\n  (0) Internal: Blas GEMM launch failed : a.shape=(1682, 500), b.shape=(500, 500), m=1682, n=500, k=500\n\t [[{{node MatMul_1}}]]\n\t [[concat_1/_31]]\n  (1) Internal: Blas GEMM launch failed : a.shape=(1682, 500), b.shape=(500, 500), m=1682, n=500, k=500\n\t [[{{node MatMul_1}}]]\n0 successful operations.\n0 derived errors ignored.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_28827/864368156.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mtic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0moptimizer_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_r\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mpre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_r\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.conda/envs/tf1/lib/python3.7/site-packages/tensorflow_core/contrib/opt/python/training/external_optimizer.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, session, feed_dict, fetches, step_callback, loss_callback, **run_kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0mpacked_bounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_packed_bounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mstep_callback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep_callback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m         optimizer_kwargs=self.optimizer_kwargs)\n\u001b[0m\u001b[1;32m    208\u001b[0m     var_vals = [\n\u001b[1;32m    209\u001b[0m         \u001b[0mpacked_var_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpacking_slice\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpacking_slice\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_packing_slices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.conda/envs/tf1/lib/python3.7/site-packages/tensorflow_core/contrib/opt/python/training/external_optimizer.py\u001b[0m in \u001b[0;36m_minimize\u001b[0;34m(self, initial_val, loss_grad_func, equality_funcs, equality_grad_funcs, inequality_funcs, inequality_grad_funcs, packed_bounds, step_callback, optimizer_kwargs)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m  \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mminimize_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mminimize_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m     message_lines = [\n",
            "\u001b[0;32m~/.conda/envs/tf1/lib/python3.7/site-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0;32m--> 624\u001b[0;31m                                 callback=callback, **options)\n\u001b[0m\u001b[1;32m    625\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m         return _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n",
            "\u001b[0;32m~/.conda/envs/tf1/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    306\u001b[0m     sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n\u001b[1;32m    307\u001b[0m                                   \u001b[0mbounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_bounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m                                   finite_diff_rel_step=finite_diff_rel_step)\n\u001b[0m\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0mfunc_and_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun_and_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.conda/envs/tf1/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_prepare_scalar_function\u001b[0;34m(fun, x0, jac, args, bounds, epsilon, finite_diff_rel_step, hess)\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;31m# calculation reduces overall function evaluations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     sf = ScalarFunction(fun, x0, args, grad, hess,\n\u001b[0;32m--> 262\u001b[0;31m                         finite_diff_rel_step, bounds, epsilon=epsilon)\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.conda/envs/tf1/lib/python3.7/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fun, x0, args, grad, hess, finite_diff_rel_step, finite_diff_bounds, epsilon)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;31m# Gradient evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.conda/envs/tf1/lib/python3.7/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.conda/envs/tf1/lib/python3.7/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mupdate_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.conda/envs/tf1/lib/python3.7/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;31m# Overwriting results in undefined behaviour because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0;31m# fun(self.x) will change self.x, with the two no longer linked.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.conda/envs/tf1/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;34m\"\"\" returns the the function value \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_if_needed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.conda/envs/tf1/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.conda/envs/tf1/lib/python3.7/site-packages/tensorflow_core/contrib/opt/python/training/external_optimizer.py\u001b[0m in \u001b[0;36mloss_grad_func_wrapper\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mloss_grad_func_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m       \u001b[0;31m# SciPy's L-BFGS-B Fortran implementation requires gradients as doubles.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m       \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_grad_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float64'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.conda/envs/tf1/lib/python3.7/site-packages/tensorflow_core/contrib/opt/python/training/external_optimizer.py\u001b[0m in \u001b[0;36meval_func\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m       augmented_fetch_vals = session.run(\n\u001b[0;32m--> 278\u001b[0;31m           augmented_fetches, feed_dict=augmented_feed_dict)\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.conda/envs/tf1/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.conda/envs/tf1/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.conda/envs/tf1/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.conda/envs/tf1/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                     \u001b[0;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[0;32m-> 1384\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInternalError\u001b[0m: 2 root error(s) found.\n  (0) Internal: Blas GEMM launch failed : a.shape=(1682, 500), b.shape=(500, 500), m=1682, n=500, k=500\n\t [[node MatMul_1 (defined at home/leegenux/.conda/envs/tf1/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1748) ]]\n\t [[concat_1/_31]]\n  (1) Internal: Blas GEMM launch failed : a.shape=(1682, 500), b.shape=(500, 500), m=1682, n=500, k=500\n\t [[node MatMul_1 (defined at home/leegenux/.conda/envs/tf1/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1748) ]]\n0 successful operations.\n0 derived errors ignored.\n\nOriginal stack trace for 'MatMul_1':\n  File \"home/leegenux/.conda/envs/tf1/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"home/leegenux/.conda/envs/tf1/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"home/leegenux/.conda/envs/tf1/lib/python3.7/site-packages/ipykernel_launcher.py\", line 17, in <module>\n    app.launch_new_instance()\n  File \"home/leegenux/.conda/envs/tf1/lib/python3.7/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n    app.start()\n  File \"home/leegenux/.conda/envs/tf1/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 712, in start\n    self.io_loop.start()\n  File \"home/leegenux/.conda/envs/tf1/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"home/leegenux/.conda/envs/tf1/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n    self._run_once()\n  File \"home/leegenux/.conda/envs/tf1/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n    handle._run()\n  File \"home/leegenux/.conda/envs/tf1/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"home/leegenux/.conda/envs/tf1/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 504, in dispatch_queue\n    await self.process_one()\n  File \"home/leegenux/.conda/envs/tf1/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 493, in process_one\n    await dispatch(*args)\n  File \"home/leegenux/.conda/envs/tf1/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 400, in dispatch_shell\n    await result\n  File \"home/leegenux/.conda/envs/tf1/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 724, in execute_request\n    reply_content = await reply_content\n  File \"home/leegenux/.conda/envs/tf1/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 387, in do_execute\n    cell_id=cell_id,\n  File \"home/leegenux/.conda/envs/tf1/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"home/leegenux/.conda/envs/tf1/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n    raw_cell, store_history, silent, shell_futures, cell_id\n  File \"home/leegenux/.conda/envs/tf1/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3029, in _run_cell\n    return runner(coro)\n  File \"home/leegenux/.conda/envs/tf1/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n    coro.send(None)\n  File \"home/leegenux/.conda/envs/tf1/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"home/leegenux/.conda/envs/tf1/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3472, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"home/leegenux/.conda/envs/tf1/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3552, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"tmp/ipykernel_28827/1516854235.py\", line 5, in <module>\n    y, reg_loss = kernel_layer(y, name=str(i))\n  File \"tmp/ipykernel_28827/1127187019.py\", line 19, in kernel_layer\n    y = tf.matmul(x, W_eff) + b\n  File \"home/leegenux/.conda/envs/tf1/lib/python3.7/site-packages/tensorflow_core/python/util/dispatch.py\", line 180, in wrapper\n    return target(*args, **kwargs)\n  File \"home/leegenux/.conda/envs/tf1/lib/python3.7/site-packages/tensorflow_core/python/ops/math_ops.py\", line 2754, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"home/leegenux/.conda/envs/tf1/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_math_ops.py\", line 6136, in mat_mul\n    name=name)\n  File \"home/leegenux/.conda/envs/tf1/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n  File \"home/leegenux/.conda/envs/tf1/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"home/leegenux/.conda/envs/tf1/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"home/leegenux/.conda/envs/tf1/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"home/leegenux/.conda/envs/tf1/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
          ]
        }
      ],
      "source": [
        "best_rmse_ep, best_mae_ep, best_ndcg_ep = 0, 0, 0\n",
        "best_rmse, best_mae, best_ndcg = float(\"inf\"), float(\"inf\"), 0\n",
        "\n",
        "time_cumulative = 0\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    for i in range(epoch_p):\n",
        "        tic = time()\n",
        "        optimizer_p.minimize(sess, feed_dict={R: train_r})\n",
        "        pre = sess.run(pred_p, feed_dict={R: train_r})\n",
        "\n",
        "        t = time() - tic\n",
        "        time_cumulative += t\n",
        "        \n",
        "        error = (test_m * (np.clip(pre, 1., 5.) - test_r) ** 2).sum() / test_m.sum()  # test error\n",
        "        test_rmse = np.sqrt(error)\n",
        "\n",
        "        error_train = (train_m * (np.clip(pre, 1., 5.) - train_r) ** 2).sum() / train_m.sum()  # train error\n",
        "        train_rmse = np.sqrt(error_train)\n",
        "\n",
        "        print('.-^-._' * 12)\n",
        "        print('PRE-TRAINING')\n",
        "        print('Epoch:', i+1, 'test rmse:', test_rmse, 'train rmse:', train_rmse)\n",
        "        print('Time:', t, 'seconds')\n",
        "        print('Time cumulative:', time_cumulative, 'seconds')\n",
        "        print('.-^-._' * 12)\n",
        "\n",
        "    for i in range(epoch_f):\n",
        "        tic = time()\n",
        "        optimizer_f.minimize(sess, feed_dict={R: train_r})\n",
        "        pre = sess.run(pred_f, feed_dict={R: train_r})\n",
        "\n",
        "        t = time() - tic\n",
        "        time_cumulative += t\n",
        "        \n",
        "        error = (test_m * (np.clip(pre, 1., 5.) - test_r) ** 2).sum() / test_m.sum()  # test error\n",
        "        test_rmse = np.sqrt(error)\n",
        "\n",
        "        error_train = (train_m * (np.clip(pre, 1., 5.) - train_r) ** 2).sum() / train_m.sum()  # train error\n",
        "        train_rmse = np.sqrt(error_train)\n",
        "\n",
        "        test_mae = (test_m * np.abs(np.clip(pre, 1., 5.) - test_r)).sum() / test_m.sum()\n",
        "        train_mae = (train_m * np.abs(np.clip(pre, 1., 5.) - train_r)).sum() / train_m.sum()\n",
        "\n",
        "        test_ndcg = call_ndcg(np.clip(pre, 1., 5.), test_r)\n",
        "        train_ndcg = call_ndcg(np.clip(pre, 1., 5.), train_r)\n",
        "\n",
        "        if test_rmse < best_rmse:\n",
        "            best_rmse = test_rmse\n",
        "            best_rmse_ep = i+1\n",
        "\n",
        "        if test_mae < best_mae:\n",
        "            best_mae = test_mae\n",
        "            best_mae_ep = i+1\n",
        "\n",
        "        if best_ndcg < test_ndcg:\n",
        "            best_ndcg = test_ndcg\n",
        "            best_ndcg_ep = i+1\n",
        "\n",
        "        print('.-^-._' * 12)\n",
        "        print('FINE-TUNING')\n",
        "        print('Epoch:', i+1, 'test rmse:', test_rmse, 'test mae:', test_mae, 'test ndcg:', test_ndcg)\n",
        "        print('Epoch:', i+1, 'train rmse:', train_rmse, 'train mae:', train_mae, 'train ndcg:', train_ndcg)\n",
        "        print('Time:', t, 'seconds')\n",
        "        print('Time cumulative:', time_cumulative, 'seconds')\n",
        "        print('.-^-._' * 12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTi_PdXJqTjh"
      },
      "outputs": [],
      "source": [
        "# Final result\n",
        "print('Epoch:', best_rmse_ep, ' best rmse:', best_rmse)\n",
        "print('Epoch:', best_mae_ep, ' best mae:', best_mae)\n",
        "print('Epoch:', best_ndcg_ep, ' best ndcg:', best_ndcg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "GLocal_K.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
